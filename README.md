# ü¶ü Dengue Monitor

**Dengue Monitor** is a **data engineering and analytics** project focused on the epidemiological analysis of dengue cases in Brazil, using **real-scale data (hundreds of thousands of records)** and interactive dashboards.

The goal of the project is to demonstrate **technical capability**, **professional best practices**, and **data-driven decision making**, with a strong emphasis on **performance**, **data engineering**, and **analytical visualization**.

---

## üéØ Objective

The **Dengue Monitor** aims to consolidate large volumes of dengue notification data, apply **efficient database-level aggregations**, and expose **dashboards and analytical endpoints** for:

* Temporal analysis (epidemiological year)
* Geographic analysis (state and municipality)
* Demographic analysis (age range and gender)

The project was designed to:

* Scale to **hundreds of thousands of records**
* Minimize repeated database queries
* Demonstrate proficiency in **analytical SQL**, **data modeling**, **caching**, **performance optimization**, and **analytical APIs**

---

## üèóÔ∏è Overall Architecture

```text
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   CSV / API  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Database (PostgreSQL)    ‚îÇ
‚îÇ - dengue_cases           ‚îÇ
‚îÇ - materialized views     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        Data Layer        ‚îÇ
‚îÇ Repositories + Cache     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚ñº              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   FastAPI    ‚îÇ ‚îÇ   Dashboard (UI)     ‚îÇ
‚îÇ Analytics API‚îÇ ‚îÇ Streamlit + Plotly   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üß± Technology Stack

### Backend / Data

* **Python 3.12+**
* **SQLAlchemy**
* **Alembic** (migrations)
* **PostgreSQL** (analytical queries and aggregations)

### API

* **FastAPI**
* **Pydantic** (schemas)
* **Uvicorn**

The API exposes **analytical endpoints** consumed by the dashboard and allows future integration with other services.

### Visualization

* **Streamlit**
* **Plotly**

### Data Engineering

* Materialized Views
* Optimized indexes
* In-memory caching
* Clear separation between **Data Layer**, **API**, and **UI**

---

## üóÇÔ∏è Project Structure

```text
dengue-monitor/
‚îÇ
‚îú‚îÄ‚îÄ dashboard/
‚îÇ   ‚îú‚îÄ‚îÄ app.py          # Streamlit app
‚îÇ   ‚îî‚îÄ‚îÄ utils.py        # UI helpers
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ lookups/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ loader.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ municipios.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ufs.json
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ transformers/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ age.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ analysis.py
‚îÇ   ‚îú‚îÄ‚îÄ enums.py
‚îÇ   ‚îú‚îÄ‚îÄ process_data.py
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ visualization/
‚îÇ       ‚îú‚îÄ‚îÄ matplotlib.py
‚îÇ       ‚îú‚îÄ‚îÄ plotly.py
‚îÇ       ‚îî‚îÄ‚îÄ seaborn.py
‚îÇ
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ repositories/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dengue_repository.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ database.py
‚îÇ   ‚îî‚îÄ‚îÄ models.py
‚îÇ
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ location_service.py
‚îÇ   ‚îú‚îÄ‚îÄ routes.py
‚îÇ   ‚îî‚îÄ‚îÄ schemas.py
‚îÇ
‚îú‚îÄ‚îÄ alembic/
‚îÇ   ‚îî‚îÄ‚îÄ versions/       # Migrations
‚îÇ
‚îú‚îÄ‚îÄ main.py             # FastAPI entrypoint
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

---

## üóÑÔ∏è Database

### Main Table

**dengue_cases**

Stores raw dengue notification records.

Key columns:

* `nu_ano` ‚Äî epidemiological year
* `sg_uf_not` ‚Äî reporting state (UF)
* `id_municip` ‚Äî municipality
* `idade` ‚Äî patient age
* `cs_sexo` ‚Äî gender (M, F, I)

### Materialized Views

The project relies on **materialized views** to avoid expensive real-time aggregations.

Example:

```sql
CREATE MATERIALIZED VIEW dengue_by_age_gender AS
SELECT
    sg_uf_not,
    nu_ano,
    FLOOR(idade / 10) * 10 AS faixa_inicio,
    cs_sexo,
    COUNT(*) AS casos
FROM dengue_cases
WHERE idade IS NOT NULL
GROUP BY sg_uf_not, nu_ano, faixa_inicio, cs_sexo;
```

‚úîÔ∏è Fast queries
‚úîÔ∏è Reduced database load
‚úîÔ∏è Ideal for dashboards and analytical APIs

---

## ‚ö° Performance & Best Practices

* Streamlit data caching
* Database-level aggregations
* Strategic indexing
* Avoids excessive database calls
* Clear separation between **UI**, **API**, and **Data Layer**

---

## üîÅ Migrations (Alembic)

Adopted standard:

* `revision`: random ID generated by Alembic
* `down_revision`: explicit dependency reference
* Descriptive migration file names

Example:

```bash
alembic revision -m "create materialized view dengue_by_age_gender"
```

This approach ensures:

* Linear migration history
* Schema reproducibility
* Easy rollback

---

## üöÄ How to Run

### 1Ô∏è‚É£ Create virtual environment

```bash
python -m venv venv
source venv/bin/activate  # Linux/macOS
venv\Scripts\Activate.ps1 # Windows
```

### 2Ô∏è‚É£ Install dependencies

```bash
pip install -r requirements.txt
```

### 3Ô∏è‚É£ Configure environment

```bash
cp .env.example .env
```

Set the database environment variables.

### 4Ô∏è‚É£ Run migrations

```bash
alembic upgrade head
```

### 5Ô∏è‚É£ Download the dengue CSV

Access the official portal:

[https://dadosabertos.saude.gov.br/dataset/arboviroses-dengue](https://dadosabertos.saude.gov.br/dataset/arboviroses-dengue)

* Download the CSV file
* Create the directory:

```text
data/raw/
```

* Place the CSV file inside this folder

> This directory is intentionally excluded from version control.

### 6Ô∏è‚É£ Process and load the data

From the **data/** directory:

```bash
python process_data.py
```

This script:

* Reads the raw CSV
* Applies sampling logic (100 records / month / UF)
* Normalizes fields
* Inserts data into PostgreSQL

### 7Ô∏è‚É£ Start the FastAPI server

```bash
uvicorn main:app --reload
```

The API exposes analytical endpoints consumed by the dashboard.

### 8Ô∏è‚É£ Start the dashboard

```bash
streamlit run dashboard/app.py
```

---

## ü§ù Contribution

Contributions are welcome!

1. Fork the project
2. Create a branch (`feat/my-feature`)
3. Commit following **Conventional Commits**
4. Open a Pull Request

---

## üìÑ License

This project is distributed under the MIT License.

---

## üë®‚Äçüíª Author

Project developed by **Jefferson** as an **advanced study and technical portfolio** in:

* Data Engineering
* Epidemiological Analysis
* Analytical Visualization
